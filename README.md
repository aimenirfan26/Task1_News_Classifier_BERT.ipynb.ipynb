# ğŸ“° Task 1: News Topic Classifier Using BERT

## ğŸ“Œ Description  
Fine-tuned BERT model to classify news headlines into **World**, **Business**, **Sports**, and **Sci/Tech** using HuggingFace and Gradio.  

---

## ğŸ“– Extended Description  
This project explores **Natural Language Processing (NLP)** using **BERT (Bidirectional Encoder Representations from Transformers)**.  
The model is trained and fine-tuned on the **AG News dataset**, which contains thousands of labeled news headlines.  

### ğŸ”¹ Key Features
- âœ… Preprocessing and tokenization with HuggingFace `transformers`.  
- âœ… Fine-tuning BERT for **multi-class classification**.  
- âœ… Evaluation using **accuracy** and **F1 score**.  
- âœ… Interactive testing with **Gradio app** (enter a headline â†’ see predicted category).  

### ğŸ”¹ Example Output
**Input:**  
`"Apple announces new AI-powered iPhone with advanced features."`  

**Output:**  
`Predicted Category: Sci/Tech | Confidence: 0.91`  

---

## âš™ï¸ Tech Stack
- Python ğŸ  
- PyTorch ğŸ”¥  
- HuggingFace Transformers ğŸ¤—  
- Gradio ğŸ¨  

---

## ğŸš€ Future Improvements
- Add support for showing **top-3 predictions** with probabilities.  
- Deploy on **HuggingFace Spaces** or **Streamlit Cloud**.  
- Train with larger datasets for better accuracy.  

---

âœï¸ *This project was developed as part of an internship task to learn transformer models and text classification.*
